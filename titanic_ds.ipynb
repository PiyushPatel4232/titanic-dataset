{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 eda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_path = \"C:/Users/PIYUSH PATEL/Downloads/titanic_disaster_dataset/train.csv\"\n",
    "test_path = \"C:/Users/PIYUSH PATEL/Downloads/titanic_disaster_dataset/test.csv\"\n",
    "\n",
    "\n",
    "train_df= pd.read_csv(train_path)\n",
    "test_df=pd.read_csv(test_path)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.info())\n",
    "\n",
    "# üìä Step 1: Exploratory Data Analysis (EDA)\n",
    "# üîç Dataset Overview\n",
    "# The train dataset has 891 entries with 12 columns.\n",
    "# The Survived column (0 = No, 1 = Yes) is our target variable.\n",
    "# The dataset contains both numerical & categorical data.\n",
    "# üìå Key Observations\n",
    "# Missing values:\n",
    "# Age has 177 missing values.\n",
    "# Cabin has many missing values (687 out of 891).\n",
    "# Embarked has 2 missing values.\n",
    "# Important Columns:\n",
    "# Pclass, Sex, Age, SibSp, Parch, Fare, and Embarked seem useful for prediction.\n",
    "# Name, Ticket, and Cabin might not be useful directly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Next Step: Data Cleaning\n",
    "# We'll handle missing values and drop unnecessary columns. Let's clean the data! üöÄ \n",
    "\n",
    "# filling missing age with the value median in age average nikal ke dal denge\n",
    "train_df[\"Age\"].fillna(train_df[\"Age\"].median(),inplace=True)\n",
    "\n",
    "#filling embark with most common category\n",
    "train_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mode()[0],inplace=True)\n",
    "#mode ke age 0 likha hai kyunki 0 likhne se sabse pehla common element ko lelega like agar 1 likhta toh second most common element ko leleta jo bhi embarked column mai hota\n",
    "\n",
    "#drop cabin and ticket column cabin isliye kyunki usme bohot missing hai and ticket sabka alag hoga jo jyda contribute nhi krega aur ese data ko ml model mai useless hote hai so isko drp krdenge\n",
    "train_df.drop(columns=[\"Cabin\",\"Ticket\"],inplace=True)\n",
    "\n",
    "#verify that missing values are handeled\n",
    "missing_values=train_df.isnull().sum()\n",
    "\n",
    "missing_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Next Step: Feature Engineering\n",
    "# We need to:\n",
    "\n",
    "# Convert categorical data (Sex, Embarked) into numerical format.\n",
    "# Create new useful features (e.g., FamilySize = SibSp + Parch).\n",
    "train_df[\"Sex\"]=train_df[\"Sex\"].map({\"male\":0,\"female\":1})\n",
    "train_df[\"Embarked\"]=train_df[\"Embarked\"].map({\"S\":0,\"C\":1,\"Q\":2})\n",
    "\n",
    "#naya feature banayenge jisme 2 colom ko add krdenge like sibsp iska matlab Number of Siblings/Spouses Aboard aur Number of parents/children the passenger had on board.\n",
    "# isme humlog sari famil memebers ko add krdenge\n",
    "\n",
    "train_df[\"Familysize\"]=train_df[\"SibSp\"]+train_df[\"Parch\"]\n",
    "\n",
    "#drop name and passenger id ye apne ml model mai kisi kaam ki nahi\n",
    "train_df.drop(columns=[\"Name\",\"PassengerId\"],inplace=True)\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "# We have successfully transformed the dataset:\n",
    "# ‚úÖ Encoded categorical variables:\n",
    "\n",
    "# Sex: (Male ‚Üí 0, Female ‚Üí 1)\n",
    "# Embarked: (S ‚Üí 0, C ‚Üí 1, Q ‚Üí 2)\n",
    "# ‚úÖ Created a new feature:\n",
    "\n",
    "# FamilySize = SibSp + Parch (total number of family members onboard).\n",
    "# ‚úÖ Dropped unnecessary columns:\n",
    "\n",
    "# Name, PassengerId (not needed for ML).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• Full Summary in One Shot\n",
    "# 1Ô∏è‚É£ train_test_split ‚Üí Data ka 80% training, 20% testing ke liye split karta hai.\n",
    "# 2Ô∏è‚É£ StandardScaler ‚Üí Values ko normalize karta hai so that sab ek scale pe ho.\n",
    "# 3Ô∏è‚É£ LogisticRegression ‚Üí Binary classification ke liye model import karta hai.\n",
    "# 4Ô∏è‚É£ DecisionTreeClassifier ‚Üí Tree-based classification model import karta hai.\n",
    "# 5Ô∏è‚É£ accuracy_score & classification_report ‚Üí Model ki performance check karne ke liye use hota hai.\n",
    "\n",
    "\n",
    "# üí° Simple Example Analogy\n",
    "# üëâ Soch ek Cricket Match hai:\n",
    "\n",
    "# train_test_split ‚Üí Practice match aur Real match alag karta hai.\n",
    "# StandardScaler ‚Üí Sab players ko ek level pe practice karata hai.\n",
    "# LogisticRegression ‚Üí Simple decision leta hai (Win/Loss) based on stats.\n",
    "# DecisionTreeClassifier ‚Üí Step-by-step decision making karta hai (If-Else logic se).\n",
    "# accuracy_score ‚Üí Kitne sahi predict kiye, batting average jaisa.\n",
    "# classification_report ‚Üí Detailed stats deta hai jaise strike rate, boundaries, wickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Next Step: Model Training\n",
    "# Now, we will:\n",
    "\n",
    "# Split the data into training & testing sets.\n",
    "# Train Logistic Regression & Decision Tree models.\n",
    "# Evaluate their performance.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(train_df.columns)\n",
    "\n",
    "#define feature (x) and target (y)\n",
    "x = train_df.drop(columns=[\"Survived\"])# input featuers (sab columns except 'survived') isme sab colum rakh raha hai bas survived ko nhi kyunki iski ko toh predict krna hai using other columns\n",
    "y = train_df[\"Survived\"]# Target variable (jo predict krna hai like 1 ki jaan bachi and 0 ki jaan nhi bachi)\n",
    "\n",
    "#train-test Split\n",
    "X_train,X_val,y_train,y_val = train_test_split(x,y, test_size=0.2,random_state=42)\n",
    "#same split number rakhenge 42 random split mai isliye rakha kyunki 42 famous hai aur har baar ek hi ratio mai split hoga toh\n",
    "# accuracy ek saman ayegi aur productivity badh jayegi\n",
    "\n",
    "#standardize features (only for logistic regression)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "x_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# train loggistic regressi0on method\n",
    "log_reg = LogisticRegression()  #model ka object banaya \n",
    "log_reg.fit(X_train_scaled,y_train) # model ko train kiya (feateures and target pe)\n",
    "\n",
    "#train decision tree model\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=5,random_state=42)#model ka object\n",
    "dtree.fit(X_train_scaled,y_train)#ensure model is trained\n",
    "#max_depth=5 taki overfit na hojaye\n",
    "#decission tree ek if else logic wala model hai\n",
    "\n",
    "#model prediction\n",
    "log_reg_preds = log_reg.predict(x_val_scaled)\n",
    "dtree_preds = dtree.predict(X_val) #desicion tree predictions\n",
    "\n",
    "\n",
    "#evaluate model\n",
    "log_reg_acc = accuracy_score(y_val,log_reg_preds)# Logistic Regression Accuracy\n",
    "dtree_acc = accuracy_score(y_val,dtree_preds)# Decision Tree Accuracy\n",
    "# Check kar rahe hain ki model kitne sahi predictions kar raha hai\n",
    "\n",
    "#detailed model evaluation \n",
    "log_reg_report = classification_report(y_val,log_reg_preds) #logisctic regression report\n",
    "dtree_report=classification_report (y_val,dtree_preds) #decision tree report\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "print(\"Decision Tree Accuracy:\", dtree_acc)\n",
    "print(\"Logistic Regression Report:\\n\", log_reg_report)\n",
    "print(\"Decision Tree Report:\\n\", dtree_report)\n",
    "\n",
    "# üî• Full Summary\n",
    "# 1Ô∏è‚É£ Feature & Target Select ‚Üí X = train_df.drop(\"Survived\"), y = train_df[\"Survived\"]\n",
    "# 2Ô∏è‚É£ Train-Test Split ‚Üí train_test_split(X, y, test_size=0.2)\n",
    "# 3Ô∏è‚É£ Scaling (Only for Logistic Regression) ‚Üí StandardScaler()\n",
    "# 4Ô∏è‚É£ Logistic Regression Train ‚Üí log_reg.fit(X_train_scaled, y_train)\n",
    "# 5Ô∏è‚É£ Decision Tree Train ‚Üí dtree.fit(X_train, y_train)\n",
    "# 6Ô∏è‚É£ Predictions ‚Üí log_reg.predict(), dtree.predict()\n",
    "# 7Ô∏è‚É£ Accuracy Check ‚Üí accuracy_score()\n",
    "# 8Ô∏è‚É£ Detailed Report ‚Üí classification_report()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Perform the same preprocessing on test data as we did on train data\n",
    "test_df[\"Age\"].fillna(train_df[\"Age\"].median(), inplace=True)\n",
    "test_df[\"Embarked\"].fillna(train_df[\"Embarked\"].mode()[0], inplace=True)\n",
    "test_df[\"Fare\"].fillna(train_df[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "# Convert categorical variables\n",
    "test_df[\"Sex\"] = test_df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "test_df[\"Embarked\"] = test_df[\"Embarked\"].map({\"S\": 0, \"C\": 1, \"Q\": 2})\n",
    "\n",
    "# Create FamilySize feature\n",
    "test_df[\"Familysize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "test_ids = test_df[\"PassengerId\"]  # Save PassengerId for final submission\n",
    "test_df.drop(columns=[\"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"], inplace=True)\n",
    "\n",
    "# Standardize test features for Logistic Regression\n",
    "test_scaled = scaler.transform(test_df)\n",
    "\n",
    "# Predict using Logistic Regression\n",
    "log_reg_preds_test = log_reg.predict(test_scaled)\n",
    "\n",
    "# Predict using Decision Tree\n",
    "dtree_preds_test = dtree.predict(test_df)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_log_reg = pd.DataFrame({\"PassengerId\": test_ids, \"Survived\": log_reg_preds_test})\n",
    "submission_dtree = pd.DataFrame({\"PassengerId\": test_ids, \"Survived\": dtree_preds_test})\n",
    "\n",
    "# Display first few rows of the predictions\n",
    "submission_log_reg.head(), submission_dtree.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
